<div align="center">

# ğŸ§  Cog-RAG

**Cognitive-Inspired Dual-Hypergraph with Theme Alignment Retrieval-Augmented Generation**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

[English](#overview) | [ä¸­æ–‡](#æ¦‚è¿°)

</div>

---

## Overview

**Cog-RAG** is a cognitive-inspired retrieval-augmented generation framework that utilizes dual-hypergraph structures with theme alignment for enhanced knowledge retrieval and question answering. Unlike traditional RAG systems that rely on simple vector similarity search, Cog-RAG models complex multi-entity relationships through hypergraphs and implements a two-stage theme-entity alignment mechanism inspired by human cognitive processes.

### âœ¨ Key Features

- ğŸ”— **Dual-Hypergraph Architecture**: Separates entity-level and theme-level knowledge representation
- ğŸ¯ **High-Order Relationship Modeling**: Captures multi-entity relationships beyond binary edges
- ğŸ§  **Cognitive-Inspired Two-Stage Retrieval**: Theme alignment followed by entity alignment
- ğŸ”„ **Multiple Query Modes**: Supports various retrieval strategies for different use cases
- ğŸ“¦ **Easy Integration**: Simple API design compatible with various LLM providers

### ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Cog-RAG System                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Documents  â”‚â”€â”€â”€â–¶â”‚   Chunking  â”‚â”€â”€â”€â–¶â”‚  Entity Extraction  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                   â”‚              â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”          â”‚
â”‚         â–¼                                             â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Entity-Relation â”‚                    â”‚   Key-Theme      â”‚   â”‚
â”‚  â”‚   Hypergraph     â”‚                    â”‚   Hypergraph     â”‚   â”‚
â”‚  â”‚                  â”‚                    â”‚                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”   â”‚                    â”‚  â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ E â”‚â”€â”€â”€â”‚ E â”‚   â”‚                    â”‚  â”‚ K â”‚â”€â”€â”€â”‚ K â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”¬â”€â”˜   â””â”€â”¬â”€â”˜   â”‚                    â”‚  â””â”€â”¬â”€â”˜   â””â”€â”¬â”€â”˜   â”‚   â”‚
â”‚  â”‚    â”‚   â•²   â”‚     â”‚                    â”‚    â”‚   â•²   â”‚     â”‚   â”‚
â”‚  â”‚    â”‚    â•²  â”‚     â”‚                    â”‚    â”‚    â•²  â”‚     â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”´â”€â”  â”Œâ”´â”€â”€â”    â”‚                    â”‚  â”Œâ”€â”´â”€â”  â”Œâ”´â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚ E â”‚â”€â”€â”‚ E â”‚    â”‚                    â”‚  â”‚ K â”‚â”€â”€â”‚ K â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜    â”‚                    â”‚  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                                       â”‚              â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                              â–¼                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                    â”‚  Two-Stage Query â”‚                         â”‚
â”‚                    â”‚  Theme â†’ Entity  â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                             â–¼                                    â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                    â”‚   LLM Response   â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Installation

### From Source (Recommended)

```bash
# Clone the repository
git clone https://github.com/haoohu/Cog-RAG.git
cd Cog-RAG

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in development mode
pip install -e .

# Or install with development dependencies
pip install -e ".[dev]"
```

### From PyPI (Coming Soon)

```bash
pip install cograg
```

### Requirements

- Python >= 3.10
- See `requirements.txt` for full dependency list

## ğŸš€ Quick Start

### 1. Configure Your LLM API

Copy the configuration template and set your API credentials:

```bash
cp config_temp.py my_config.py
```

Edit `my_config.py`:

```python
# LLM Configuration
LLM_BASE_URL = "https://api.openai.com/v1"  # Or your custom endpoint
LLM_API_KEY = "your-api-key"
LLM_MODEL = "gpt-4o-mini"

# Embedding Configuration
EMB_BASE_URL = "https://api.openai.com/v1"
EMB_API_KEY = "your-api-key"
EMB_MODEL = "text-embedding-3-small"
EMB_DIM = 1536
```

### 2. Basic Usage

```python
import asyncio
import numpy as np
from cograg import CogRAG, QueryParam
from cograg.llm import openai_complete_if_cache, openai_embedding
from cograg.utils import EmbeddingFunc

# Configure LLM function
async def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
    return await openai_complete_if_cache(
        "gpt-4o-mini",
        prompt,
        system_prompt=system_prompt,
        history_messages=history_messages,
        api_key="your-api-key",
        base_url="https://api.openai.com/v1",
        **kwargs,
    )

# Configure embedding function
async def embedding_func(texts: list[str]) -> np.ndarray:
    return await openai_embedding(
        texts,
        model="text-embedding-3-small",
        api_key="your-api-key",
        base_url="https://api.openai.com/v1",
    )

# Initialize Cog-RAG
rag = CogRAG(
    working_dir="./my_rag_cache",
    llm_model_func=llm_model_func,
    embedding_func=EmbeddingFunc(
        embedding_dim=1536,
        max_token_size=8192,
        func=embedding_func
    ),
)

# Insert documents
with open("your_document.txt", "r") as f:
    text = f.read()
rag.insert(text)

# Query with different modes
# Full Cog-RAG (two-stage theme-entity alignment)
response = rag.query(
    "What are the main themes in this document?",
    param=QueryParam(mode="cog")
)
print(response)
```

### 3. Query Modes

Cog-RAG supports multiple query modes:

| Mode | Description | Use Case |
|------|-------------|----------|
| `cog` | Full two-stage retrieval (Theme â†’ Entity) | Best overall performance |
| `cog-hybrid` | Parallel theme and entity retrieval | Balanced approach |
| `cog-entity` | Entity-only retrieval | Detail-focused queries |
| `cog-theme` | Theme-only retrieval | High-level queries |
| `naive` | Traditional vector search | Baseline comparison |

```python
# Theme-focused query
response = rag.query(
    "What is the overall narrative?",
    param=QueryParam(mode="cog-theme")
)

# Entity-focused query  
response = rag.query(
    "What did Character X do?",
    param=QueryParam(mode="cog-entity")
)

# Hybrid query
response = rag.query(
    "How do the themes relate to the characters?",
    param=QueryParam(mode="cog-hybrid")
)
```

## ğŸ“– Documentation

### Core Components

#### CogRAG Class

The main class for the Cog-RAG system:

```python
from cograg import CogRAG

rag = CogRAG(
    working_dir="./cache",           # Directory for storing indices
    chunk_token_size=1200,           # Size of text chunks
    chunk_overlap_token_size=100,    # Overlap between chunks
    llm_model_func=your_llm_func,    # Your LLM function
    embedding_func=your_embed_func,  # Your embedding function
    llm_model_max_async=16,          # Max concurrent LLM calls
)
```

#### QueryParam Class

Configure query behavior:

```python
from cograg import QueryParam

param = QueryParam(
    mode="cog",                      # Query mode
    only_need_context=False,         # Return only context (no LLM response)
    top_k=60,                        # Number of items to retrieve
    max_token_for_text_unit=1600,    # Max tokens for source text
    max_token_for_entity_context=300,# Max tokens for entity descriptions
    max_token_for_relation_context=1600,  # Max tokens for relationships
)
```

### Storage Architecture

Cog-RAG uses multiple storage backends:

- **JsonKVStorage**: Key-value storage for documents and chunks
- **NanoVectorDBStorage**: Vector database for similarity search
- **HypergraphStorage**: Hypergraph database for complex relationships

### Hypergraph Structure

#### Entity-Relation Hypergraph

- **Vertices**: Entities with type, description, and properties
- **Low-order Hyperedges**: Binary relationships between entity pairs
- **High-order Hyperedges**: Multi-entity relationships (N â‰¥ 3)

#### Key-Theme Hypergraph

- **Vertices**: Key entities with importance scores
- **Hyperedges**: Themes connecting multiple key entities

## ğŸ”§ Advanced Configuration

### Custom LLM Integration

```python
from cograg.llm import openai_complete_if_cache

# Use Azure OpenAI
async def azure_llm_func(prompt, **kwargs):
    return await azure_openai_complete_if_cache(
        model="your-deployment",
        prompt=prompt,
        api_key="your-key",
        base_url="your-endpoint",
        **kwargs
    )

# Use local models (via API-compatible servers)
async def local_llm_func(prompt, **kwargs):
    return await openai_complete_if_cache(
        model="llama-3",
        prompt=prompt,
        base_url="http://localhost:8000/v1",
        **kwargs
    )
```

### Custom Embedding Models

```python
from cograg.utils import EmbeddingFunc

# Use sentence-transformers
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')

async def local_embedding(texts: list[str]):
    return model.encode(texts)

embedding_func = EmbeddingFunc(
    embedding_dim=384,
    max_token_size=512,
    func=local_embedding
)
```

## ğŸ“Š Benchmarks

Coming soon...

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Setup

```bash
# Clone and install dev dependencies
git clone https://github.com/haoohu/Cog-RAG.git
cd Cog-RAG
pip install -e ".[dev]"

# Run tests
pytest

# Format code
black cograg/
isort cograg/

# Type checking
mypy cograg/
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“š Citation

If you use Cog-RAG in your research, please cite:

```bibtex
@article{cograg2024,
  title={Cog-RAG: Cognitive-Inspired Dual-Hypergraph with Theme Alignment Retrieval-Augmented Generation},
  author={},
  journal={},
  year={2024}
}
```

## ğŸ™ Acknowledgements

- [nano-vectordb](https://github.com/gusye1234/nano-vectordb) for lightweight vector storage
- [hypergraph-db](https://github.com/iMoonLab/hypergraph-db) for hypergraph storage
- [OpenAI](https://openai.com/) for LLM and embedding APIs

## ğŸ“§ Contact

For questions or feedback, please open an issue or contact us at [your-email@example.com].

---

<div align="center">

**â­ Star us on GitHub if you find this project useful! â­**

</div>

---

## æ¦‚è¿°

**Cog-RAG** æ˜¯ä¸€ä¸ªè®¤çŸ¥å¯å‘çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ï¼Œåˆ©ç”¨åŒè¶…å›¾ç»“æ„å’Œä¸»é¢˜å¯¹é½æœºåˆ¶æ¥å¢å¼ºçŸ¥è¯†æ£€ç´¢å’Œé—®ç­”èƒ½åŠ›ã€‚ä¸ä¾èµ–ç®€å•å‘é‡ç›¸ä¼¼åº¦æœç´¢çš„ä¼ ç»Ÿ RAG ç³»ç»Ÿä¸åŒï¼ŒCog-RAG é€šè¿‡è¶…å›¾å»ºæ¨¡å¤æ‚çš„å¤šå®ä½“å…³ç³»ï¼Œå¹¶å®ç°äº†å—äººç±»è®¤çŸ¥è¿‡ç¨‹å¯å‘çš„ä¸¤é˜¶æ®µä¸»é¢˜-å®ä½“å¯¹é½æœºåˆ¶ã€‚

### âœ¨ ä¸»è¦ç‰¹æ€§

- ğŸ”— **åŒè¶…å›¾æ¶æ„**ï¼šåˆ†ç¦»å®ä½“å±‚å’Œä¸»é¢˜å±‚çš„çŸ¥è¯†è¡¨ç¤º
- ğŸ¯ **é«˜é˜¶å…³ç³»å»ºæ¨¡**ï¼šæ•è·è¶…è¶ŠäºŒå…ƒè¾¹çš„å¤šå®ä½“å…³ç³»
- ğŸ§  **è®¤çŸ¥å¯å‘çš„ä¸¤é˜¶æ®µæ£€ç´¢**ï¼šå…ˆä¸»é¢˜å¯¹é½ï¼Œåå®ä½“å¯¹é½
- ğŸ”„ **å¤šç§æŸ¥è¯¢æ¨¡å¼**ï¼šæ”¯æŒä¸åŒä½¿ç”¨åœºæ™¯çš„å¤šç§æ£€ç´¢ç­–ç•¥
- ğŸ“¦ **æ˜“äºé›†æˆ**ï¼šç®€æ´çš„ API è®¾è®¡ï¼Œå…¼å®¹å„ç§ LLM æä¾›å•†

è¯¦ç»†çš„ä¸­æ–‡æ–‡æ¡£è¯·å‚è€ƒ [docs/README_zh.md](docs/README_zh.md)ã€‚






